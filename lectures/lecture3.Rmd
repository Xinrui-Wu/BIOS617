---
title: "BIOS 617 - Lecture 3"
author: "Walter Dempsey"
date: "1/15/2019"
output:
  beamer_presentation: default
  ioslides_presentation:
    css: styles.css
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

## SRS without replacement

- Generate sample of size $n$ from $N$ by sampling without replacement
- Given $j$ *unique* selected units, the next unit is sampled uniformly at random from remaining $N-j$ units each with probability $1/(N-j)$.
- There are ${N \choose n} = \frac{N!}{n! (N-n)!}$ possible samples
- **Show**: sample mean under SRS is unbiased
- **Show**: sample variance is $(1-f) \frac{S^2}{n}$ 

## Review of unbiasedness

* What is the probability of sampling individual $j$?
$$\small
\begin{aligned}
P(I_j = 1) &= 1 - P(I_j \neq 1) \\
&= 1 - \frac{N-1}{N} \times \frac{N-2}{N-1} \times \cdots \times \frac{N-n}{N-(n-1)} \\
&= 1 - \frac{N-n}{N} = \frac{n}{N}
\end{aligned}
$$
* What is the probability of both individual $j$ and $i$ being sampled?
$$\small
\begin{aligned}
P(I_k = 1 \& I_j = 1) &=  \\
&= \frac{n}{N} \times P() \\
&= \frac{n}{N} \times P() \\
\end{aligned}
$$

## Review of unbiasedness
* Then by linearity of expectations
$$\small
E [ \bar y ] = E \left[ \frac{1}{n} \sum_j I_j Y_j \right] = \frac{1}{n} \sum_j E [ I_j  ] Y_j = \bar Y
$$ 

## A slightly more cumbersome proof

We can use the the sampling design directly instead. The number of samples $S = {N \choose n}$.
Then

$$\small
\begin{aligned}
E[ \bar y ] &= \sum_{s=1}^S P_s \bar y_s = \sum_{s=1}^S {N \choose n}^{(-1)} \frac{1}{n} \sum_{j=1}^N I^{(s)}_j Y_j \\
 &= \frac{(N-n)!n!}{n \cdot N!} \sum_{j=1}^N Q_j Y_j = \frac{(N-n)!n!}{n \cdot N!} \sum_{j=1}^N {N-1 \choose n-1} Y_j \\
 &= \frac{(N-n)!n!}{n \cdot N!} \frac{(N-1)!}{(n-1)! (N-n)!} \sum_{j=1}^N Y_j \\
 &= \frac{1}{N} \sum_{j=1}^N Y_j \\
\end{aligned}
$$

## Practice makes perfect
* Suppose $(Y_i, X_i)$ is the set of data on each participant in the population
* Suppose a selected individual can decide to not response. Let $r_i$
* Suppose we know the probability of non-response and it depends on the covariates: $\pi (X_i)$
* Estimator: $\frac{1}{n} \sum_{}$
* Unbiasedness:

$$\small
E [ \bar y ] = E \left[ \frac{1}{n} \sum_j I_j Y_j \right] = \frac{1}{n} \sum_j E [ I_j  ] Y_j = \bar Y
$$ 

## Variance calculation

Let's use prior class results on variance directly 
$$ \small
\begin{aligned}
V(\bar y) = &V \left( n{-1} \sum_{i=1}^n y_i \right) = \frac{1}{n^2} V \left( \sum_{i=1}^n y_i \right) \\
&= \frac{1}{n^2} \left[ n \cdot V(y_i) + n \cdot (n-1) \cdot \text{Cov} (y_i, y_j) \right] \\ 
&= \frac{1}{n^2} \left[ n \cdot \frac{N-1}{N} S^2 + n \cdot (n-1) \left( E[y_i y_j] - \bar Y^2 \right) \right] 
\end{aligned}
$$

## Method 2: Computing moments
$$ \small
\begin{aligned}
E[y_i y_j ] &= E \left[ \frac{y_j}{N-1} \sum_{i=1, i \neq j}^N Y_i \right] = E \left[ \frac{y_j}{N-1} (N \bar Y - y_j) \right]\\
&= \frac{1}{N-1} \left( N \bar Y^2 - E [ y_j^2 ] \right) = \frac{1}{N-1} \left( N \bar Y^2 - \bar Y^2 - \frac{N-1}{N} S^2   \right) \\
&= \bar Y^2 - \frac{S^2}{N}
\end{aligned}
$$
So the $\text{Cov} (y_i, y_j) = - \frac{S^2}{N}$ and
$$
 V(\bar y) = \frac{1}{n} \left[ (N-1)\frac{S^2}{N} - (n-1) \frac{S^2}{N}  \right] = \frac{S^2}{n} (1-f).
$$

## JITT Review/Discussion 
- We know $V (\bar y) = V\left( \frac{1}{n} \sum_{i=1}^n I_i Y_i \right)$ 
- Hint 1: $V(I_i) = f (1-f)$ and $\text{Cov}(I_i, I_j) = f \left( \frac{n-1}{N-1} - f \right)$
- Step 1: Use hint 1 to show the variance is equivalent to
$$ \small
\frac{f (1-f)}{n^2} \left[ \sum_{i=1}^N Y_i^2 - \frac{1}{N-1} \sum_{j=1}^N \sum_{i\neq j} Y_i Y_j\right]
$$
- Hint 2:
$$ \small
\sum_{j=1}^N \sum_{i=1}^N Y_i Y_j = \left( \sum_{i=1}^N Y_i \right)^2 - \sum_{i=1}^N Y_i^2
$$

- Step 2: Combine hint and variance formula to show result


## Stratified sampling designs

In many settings, there is information about the population available in the sampling frame that can be used to develop strata.

- Examples
  + Address-based samples: geographic region
  + Telephone numbers: telephone exchanges (region, cell vs. landline)

Basic idea: divide sampling frame into strata, and then sample **within** each stratum

- Why do we do this?
  + Improve efficiency (homogeneity within strata, equalize sample sizes for
subgroups we want to compare).
  + Separate study domains.
  + Implement different sampling strategies within different strata.
  + Administrative convenience.

## Stratified sampling designs: Notation

- Index strata by $h=1,\ldots, H$
- Population size within stratum $h$: $N_h$; $N = \sum_{h=1}^H N_h$.
- Proportion in stratum $h$: $P_h = N_h / N$
- Observation $i \in h$: $Y_{ih}, i = 1,\ldots, N_h$
- Population mean in stratum $h$: $\bar Y_h = N_h^{-1} \sum_{i=1}^{N_h} Y_{ih}$
- Population variance in stratum $h$: $S_h^2 = (N_h-1)^{-1} \sum_{i=1}^{N_h} (Y_{ih}-\bar Y_{h})^2$
