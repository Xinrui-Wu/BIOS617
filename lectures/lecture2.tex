% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
  ignorenonframetext,
]{beamer}
\usepackage{pgfpages}
\setbeamertemplate{caption}[numbered]
\setbeamertemplate{caption label separator}{: }
\setbeamercolor{caption name}{fg=normal text.fg}
\beamertemplatenavigationsymbolsempty
% Prevent slide breaks in the middle of a paragraph
\widowpenalties 1 10000
\raggedbottom
\setbeamertemplate{part page}{
  \centering
  \begin{beamercolorbox}[sep=16pt,center]{part title}
    \usebeamerfont{part title}\insertpart\par
  \end{beamercolorbox}
}
\setbeamertemplate{section page}{
  \centering
  \begin{beamercolorbox}[sep=12pt,center]{part title}
    \usebeamerfont{section title}\insertsection\par
  \end{beamercolorbox}
}
\setbeamertemplate{subsection page}{
  \centering
  \begin{beamercolorbox}[sep=8pt,center]{part title}
    \usebeamerfont{subsection title}\insertsubsection\par
  \end{beamercolorbox}
}
\AtBeginPart{
  \frame{\partpage}
}
\AtBeginSection{
  \ifbibliography
  \else
    \frame{\sectionpage}
  \fi
}
\AtBeginSubsection{
  \frame{\subsectionpage}
}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={BIOS 617 - Lecture 2},
  pdfauthor={Walter Dempsey},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\newif\ifbibliography
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering

\title{BIOS 617 - Lecture 2}
\author{Walter Dempsey}
\date{1/13/2019}

\begin{document}
\frame{\titlepage}

\begin{frame}{JITT Review/Discussion}
\protect\hypertarget{jitt-reviewdiscussion}{}

\end{frame}

\begin{frame}{Simple random sampling (SRS) without replacement}
\protect\hypertarget{simple-random-sampling-srs-without-replacement}{}

\begin{itemize}
\tightlist
\item
  Generate sample of size \(n\) from \(N\) by sampling without
  replacement
\item
  Given \(j\) \emph{unique} selected units, the next unit is sampled
  uniformly at random from remaining \(N-j\) units each with probability
  \(1/(N-j)\).
\item
  There are \({N \choose n} = \frac{N!}{n! (N-n)!}\) possible samples
\item
  \textbf{Show}: sample mean under SRS is unbiased
\item
  \textbf{Show}: sample variance is \((1-f) \frac{S^2}{n}\)
\end{itemize}

\end{frame}

\begin{frame}{Unbiasedness of SRS sample mean}
\protect\hypertarget{unbiasedness-of-srs-sample-mean}{}

\begin{itemize}
\tightlist
\item
  What is the probability of sampling individual \(j\)? \[\small
  \begin{aligned}
  P(I_j = 1) &= 1 - P(I_j \neq 1) \\
  &= 1 - \frac{N-1}{N} \times \frac{N-2}{N-1} \times \cdots \times \frac{N-n}{N-(n-1)} \\
  &= 1 - \frac{N-n}{N} = \frac{n}{N}
  \end{aligned}
  \]
\item
  Then by linearity of expectations \[\small
  E [ \bar y ] = E \left[ \frac{1}{n} \sum_j I_j Y_j \right] = \frac{1}{n} \sum_j E [ I_j  ] Y_j = \bar Y
  \]
\end{itemize}

\end{frame}

\begin{frame}{A slightly more cumbersome proof}
\protect\hypertarget{a-slightly-more-cumbersome-proof}{}

We can use the the sampling design directly instead. The number of
samples \(S = {N \choose n}\). Then

\[\small
\begin{aligned}
E[ \bar y ] &= \sum_{s=1}^S P_s \bar y_s = \sum_{s=1}^S {N \choose n}^{(-1)} \frac{1}{n} \sum_{j=1}^N I^{(s)}_j Y_j \\
 &= \frac{(N-n)!n!}{n \cdot N!} \sum_{j=1}^N Q_j Y_j = \frac{(N-n)!n!}{n \cdot N!} \sum_{j=1}^N {N-1 \choose n-1} Y_j \\
 &= \frac{(N-n)!n!}{n \cdot N!} \frac{(N-1)!}{(n-1)! (N-n)!} \sum_{j=1}^N Y_j \\
 &= \frac{1}{N} \sum_{j=1}^N Y_j \\
\end{aligned}
\]

\end{frame}

\begin{frame}{Variance of \(\bar y\)}
\protect\hypertarget{variance-of-bar-y}{}

\[ \small
\begin{aligned}
&E \left[ \left( \bar y - \bar Y \right)^2  \right] \\
= &E \left[ \left( n^{-1} \sum_{j=1}^N I_j^{(s)} (Y_i - \bar Y) \right)^2  \right] \\
= &\frac{1}{n^2} \left(  \sum_{i,j=1}^N E \left[I_i^{(s)} I_j^{(s)} \right] (Y_i - \bar Y) (Y_j - \bar Y)  \right) \\
= &\frac{1}{n^2}  \left( \sum_{i}^N \frac{n}{N} (Y_i - \bar Y)^2  + 
\sum_{i \neq j} \frac{n}{N} \cdot \frac{n-1}{N-1} (Y_i - \bar Y) (Y_j - \bar Y)  \right) \\
= &\frac{1}{n \cdot N}  \left( \left(1 - \frac{n-1}{N-1} \right) \sum_{i}^N (Y_i - \bar Y)^2  + 
\frac{n-1}{N-1}\left[ \sum_{i=1}^N  (Y_i - \bar Y) \right]^2  \right) \\
= &\frac{N-n}{N} \frac{S^2}{n} + 0 = (1-f)\frac{S^2}{n}
\end{aligned}
\]

\end{frame}

\begin{frame}{Method 2: Symmetry arguments}
\protect\hypertarget{method-2-symmetry-arguments}{}

Let's use prior class results on variance directly \[ \small
\begin{aligned}
V(\bar y) = &V \left( n{-1} \sum_{i=1}^n y_i \right) = \frac{1}{n^2} V \left( \sum_{i=1}^n y_i \right) \\
&= \frac{1}{n^2} \left[ n \cdot V(y_i) + n \cdot (n-1) \cdot \text{Cov} (y_i, y_j) \right] \\ 
&= \frac{1}{n^2} \left[ n \cdot \frac{N-1}{N} S^2 + n \cdot (n-1) \left( E[y_i y_j] - \bar Y^2 \right) \right] 
\end{aligned}
\]

\end{frame}

\begin{frame}{Method 2: Computing moments}
\protect\hypertarget{method-2-computing-moments}{}

\[ \small
\begin{aligned}
E[y_i y_j ] &= E \left[ \frac{y_j}{N-1} \sum_{i=1, i \neq j}^N Y_i \right] = E \left[ \frac{y_j}{N-1} (N \bar Y - y_j) \right]\\
&= \frac{1}{N-1} \left( N \bar Y^2 - E [ y_j^2 ] \right) = \frac{1}{N-1} \left( N \bar Y^2 - \bar Y^2 - \frac{N-1}{N} S^2   \right) \\
&= \bar Y^2 - \frac{S^2}{N}
\end{aligned}
\] So the \(\text{Cov} (y_i, y_j) = - \frac{S^2}{N}\) and \[
 V(\bar y) = \frac{1}{n} \left[ (N-1)\frac{S^2}{N} - (n-1) \frac{S^2}{N}  \right] = \frac{S^2}{n} (1-f).
\]

\end{frame}

\begin{frame}{Simulation study (ctd.)}
\protect\hypertarget{simulation-study-ctd.}{}

\begin{center}\includegraphics{lecture2_files/figure-beamer/heights-1} \end{center}

\end{frame}

\begin{frame}{Design-based inference: Simple example}
\protect\hypertarget{design-based-inference-simple-example}{}

\begin{itemize}
\tightlist
\item
  Population's average height is 65.5444
\item
  Population's \(S^2\) is 20.1691
\item
  Example sample w/o replacement: 25, 8, 13, 27, 14, 28, 9, 17, 31, 26
\item
  Corresponding estimate: 64.3789
\item
  Variance is 1.8152
\item
  Estimated variance is 2.6085
\end{itemize}

\end{frame}

\begin{frame}{Design-based inference: Simulation tests}
\protect\hypertarget{design-based-inference-simulation-tests}{}

\begin{itemize}
\tightlist
\item
  Population's average height is 65.5444
\item
  Population's \(S\) is 20.1691
\item
  Simulate 10,000 simple random samples
\item
  Calculate \(\bar y^{(k)}\) for the \(k\)th simulation
  (\(k=1,\ldots, 10,000\))
\item
  Compute empirical variance 1.4721
\item
  Compare with \((1-f)*S^2/n\) is 1.8152
\end{itemize}

\end{frame}

\begin{frame}{Sampling with replacement}
\protect\hypertarget{sampling-with-replacement}{}

\begin{itemize}
\tightlist
\item
  In practice, we almost never sample with replacement
\item
  Often, variance estimators are easier to compute
\item
  Usually only estimator with analytic solution
\end{itemize}

\end{frame}

\begin{frame}{Unbiased estimation of \(S^2\)}
\protect\hypertarget{unbiased-estimation-of-s2}{}

\begin{itemize}
\tightlist
\item
  Variance \((1-f) \frac{S^2}{n}\) depends on unknown quantity \(S^2\)
\item
  \textbf{Idea}: Use the sample variance as an estimator
\item
  \textbf{Question}: Is this an unbiased estimator of \(S^2\)? \[ \small
  \begin{aligned}
  E \left( s^2 \right) &= E \left( \frac{1}{n-1} \sum_{i=1}^n (y_i - \bar y)^2 \right) \\
  &= E \left( \frac{1}{n-1} \sum_{i=1}^n ( (y_i - \bar Y) - (\bar y - \bar Y))^2 \right) \\
  \end{aligned}
  \]
\item
  The cross-term is zero because \[ \small
  \sum_{i=1}^n (y_i - \bar y) (\bar y - \bar Y) =  (\bar y - \bar Y) \sum_{i=1}^n (y_i - \bar y) = 0
  \]
\end{itemize}

\end{frame}

\begin{frame}{Unbiased estimation of \(S^2\)}
\protect\hypertarget{unbiased-estimation-of-s2-1}{}

\[ \small
\begin{aligned}
&E \left( \frac{1}{n-1} \sum_{i=1}^n ( (y_i - \bar Y)^2 - (\bar y - \bar Y)^2 \right) \\
=& \frac{n}{n-1} \times \frac{N-1}{N} S^2 - \frac{n}{n-1} \frac{1}{n} S^2 (1-f) \\
=& \frac{S^2}{n-1} \left( n \frac{N-1}{N} - \left(1-\frac{n}{N} \right) \right) \\
=& \frac{S^2}{n-1} \left( \frac{n \cdot(N-1)-(N-n)}{N} \right) \\
=& \frac{S^2}{n-1} \left( \frac{N(n-1)}{N} \right) = S^2.
\end{aligned}
\]

\end{frame}

\begin{frame}{Standard errors and confidence limits}
\protect\hypertarget{standard-errors-and-confidence-limits}{}

Typically standard errors and confidence intervals are computed using a
normal approximation: \[ \small
\frac{\bar y_n - \bar Y_N}{\sqrt{\text{Var}(\bar y_n)}} \to N(0,1)
\] in distribution as \(n \to \infty\), \(N \to \infty\), and
\(n/N \to 0\).

The proof for this is beyond the scope of this course; it is a more
complex version of the standard central limit theorem (which assumes
infinite populations). A key assumption is a variant on the existence of
variance (Lindeberg condition {[}independence, not IID{]} extended to
finite population sampling):

\end{frame}

\begin{frame}{Estimating proportions under SRS}
\protect\hypertarget{estimating-proportions-under-srs}{}

\begin{itemize}
\tightlist
\item
  Let \(Y_i = 1\) is element \(i\) has a given attribute, and \(0\)
  otherwise.
\item
  \(\bar Y = M/N=P\) where

  \begin{itemize}
  \tightlist
  \item
    \(M\) is the number of elements in the population with that
    attribute
  \item
    \(P\) is the proportion of the population with the attribute
  \end{itemize}
\item
  The variance is \[ \small
  \begin{aligned}
  S^2 &= \frac{\sum_{i=1}^N (Y_i - \bar Y)}{N-1} = \frac{\sum_{i=1}^N Y_i^2 - N\bar Y)}{N-1} \\
  &= \frac{NP - NP^2}{N-1} = \frac{N \cdot P \cdot (1-P)}{N-1}
  \end{aligned}
  \]
\end{itemize}

\end{frame}

\begin{frame}{Estimating proportions under SRS}
\protect\hypertarget{estimating-proportions-under-srs-1}{}

\begin{itemize}
\tightlist
\item
  Sample proportion \(p = n^{-1} \sum_{i=1}^n y_i\) unbiased for \(P\)
\item
  Sample variance \(\frac{n p (1-p)}{n-1}\) is unbiased for \(S^2\)
\item
  \(v(p) = (1-f) \frac{p (1-p)}{n-1}\)
\item
  As \(N\) gets large \(f \to 0\) and so, for
  large\textasciitilde{}\(n\),

  \begin{itemize}
  \tightlist
  \item
    \(v(p) \to \frac{p(1-p)}{n}\)
  \item
    ``Standard'' variance for binomial variable under normal
    approximation
  \end{itemize}
\end{itemize}

\end{frame}

\begin{frame}{Design-based inference: Simulation tests}
\protect\hypertarget{design-based-inference-simulation-tests-1}{}

\begin{itemize}
\tightlist
\item
  Suppose we want to know number of students taller than 62 inches
\item
  The sample has 7 out of the 10 individuals
\item
  Population has 0.79 fraction of individuals
\item
  Sample variance is 0.233
\item
  True variance is 0.168
\end{itemize}

\end{frame}

\begin{frame}{Subdomain estimation}
\protect\hypertarget{subdomain-estimation}{}

\begin{itemize}
\item
  In some cases, we are interested in inference for a particular
  subdomain (say females, households with incomes below \$30K/year,
  businesses of a certain size, etc.)
\item
  Here the distinction is that we often cannot ascertain whether an
  element in the population is a member of the subdomain until we sample
  it.
\item
  Let \(j\) index the subdomain of interest, and \(D_{ij}\) be an
  indicator that the \(i\)th element belongs to subdomain \(j\).
\item
  Then sample estimator \(\bar y_j = n_j^{-1} \sum_{i=1}^n D_{ij} y_i\)
  with \(n_{j} = \sum_{i=1}^n D_{ij}\) is unbiased for the population
  subdomain \(\bar Y_j = N_j^{-1} \sum_{i=1}^N D_{ij} Y_i\) for
  \(N_j = \sum_{i=1}^N D_{ij}\)
\end{itemize}

\end{frame}

\begin{frame}{Subdomain estimation}
\protect\hypertarget{subdomain-estimation-1}{}

\begin{itemize}
\tightlist
\item
  The term \(n_j\) is a random variable
\item
  Variance of \(\bar y_j\) dpeends on \(n_j\), which is a random
  variable
\item
  If we condition on \(n_j\), then we have the obvious extensions:
  \[ \small
  V(\bar y_j) = (1-f) \frac{S_j^2}{n_j}, \text{ where } S_j^2 = (N_j - 1)^{-1} \sum_{i=1}^N D_{ij} (Y_i - \bar Y_j)^2
  \]
\item
  And \[ \small
  v(\bar y_j) = (1-f) \frac{s_j^2}{n_j}, \text{ where } s_j^2 = (n_j - 1)^{-1} \sum_{i=1}^n D_{ij} (y_i - \bar y_j)^2
  \]
\item
  If \(N_j\) is known, then \(f = n/N\) can be replaced by
  \(f_j = n_j / N_j\)
\end{itemize}

\end{frame}

\begin{frame}{Subdomain totals}
\protect\hypertarget{subdomain-totals}{}

\begin{itemize}
\tightlist
\item
  Unbiased estimator of the subdomain total
  \(Y_j = \sum_{i=1}^N D_{ij} Y_i\) is \[\small 
  y_j = \frac{N}{n} \sum_{i=1}^n D_{ij} y_i
  \]
\item
  Also, \(v(y_j) = \frac{N^2}{n} \tilde s^2 (1-f)\) for \[\small
  \tilde s^2 = (n-1)^{-1} \sum_{i=1}^n D_{ij} (y_i - \bar{\tilde y}_j)^2
  \] where \(\bar{\tilde y}_j = n^{-1} \sum_{i=1}^n D_{ij} y_i\)
\end{itemize}

\end{frame}

\begin{frame}{Your second JITT: 3rd proof of variance}
\protect\hypertarget{your-second-jitt-3rd-proof-of-variance}{}

\begin{itemize}
\item
  We know
  \(V (\bar y) = V\left( \frac{1}{n} \sum_{i=1}^n I_i Y_i \right)\)
\item
  Hint 1: \(V(I_i) = f (1-f)\) and
  \(\text{Cov}(I_i, I_j) = f \left( \frac{n-1}{N-1} - f \right)\)
\item
  Step 1: Use hint 1 to show the variance is equivalent to \[ \small
  \frac{f (1-f)}{n^2} \left[ \sum_{i=1}^N Y_i^2 - \frac{1}{N-1} \sum_{j=1}^N \sum_{i\neq j} Y_i Y_j\right]
  \]
\item
  Hint 2: \[ \small
  \sum_{j=1}^N \sum_{i=1}^N Y_i Y_j = \left( \sum_{i=1}^N Y_i \right)^2 - \sum_{i=1}^N Y_i^2
  \]
\item
  Step 2: Combine hint and variance formula to show result
\end{itemize}

\end{frame}

\end{document}
